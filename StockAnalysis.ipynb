{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from finta import TA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining some constants for data mining\n",
    "\"\"\"\n",
    "\n",
    "NUM_DAYS = 10000     # The number of days of historical data to retrieve\n",
    "INTERVAL = '1d'     # Sample rate of historical data\n",
    "symbol = 'SPY'      # Symbol of the desired stock\n",
    "\n",
    "# List of symbols for technical indicators\n",
    "INDICATORS = ['RSI', 'MACD', 'STOCH','ADL', 'ATR', 'MOM', 'MFI', 'ROC', 'OBV', 'CCI', 'EMV', 'VORTEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "6896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12a5e0780>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Next we pull the historical data using yfinance\n",
    "Rename the column names because finta uses the lowercase names\n",
    "\"\"\"\n",
    "\n",
    "start = (datetime.date.today() - datetime.timedelta( NUM_DAYS ) )\n",
    "end = datetime.datetime.today()\n",
    "\n",
    "data = yf.download(symbol, start=start, end=end, interval=INTERVAL)\n",
    "data.rename(columns={\"Close\": 'close', \"High\": 'high', \"Low\": 'low', 'Volume': 'volume', 'Open': 'open'}, inplace=True)\n",
    "print(len(data))\n",
    "\n",
    "tmp = data.iloc[-60:]\n",
    "tmp['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10e009208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Next we clean our data and perform feature engineering to create new technical indicator features that our\n",
    "model can learn from\n",
    "\"\"\"\n",
    "\n",
    "def _exponential_smooth(data, alpha):\n",
    "    \"\"\"\n",
    "    Function that exponentially smooths dataset so values are less 'rigid'\n",
    "    :param alpha: weight factor to weight recent values more\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.ewm(alpha=alpha).mean()\n",
    "\n",
    "data = _exponential_smooth(data, 0.65)\n",
    "\n",
    "tmp1 = data.iloc[-60:]\n",
    "tmp1['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['close', 'RSI', 'MACD', 'SIGNAL', '14 period STOCH %K', 'MFV',\n",
      "       '14 period ATR', 'MOM', '14 period MFI', 'ROC', 'OBV_x', 'OBV_y',\n",
      "       '20 period CCI', '14 period EMV', 'VIm', 'VIp', 'ema50', 'ema21',\n",
      "       'ema15', 'ema5', 'normVol'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def _get_indicator_data(data):\n",
    "    \"\"\"\n",
    "    Function that uses the finta API to calculate technical indicators used as the features\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for indicator in INDICATORS:\n",
    "        ind_data = eval('TA.' + indicator + '(data)')\n",
    "        if not isinstance(ind_data, pd.DataFrame):\n",
    "            ind_data = ind_data.to_frame()\n",
    "        data = data.merge(ind_data, left_index=True, right_index=True)\n",
    "    data.rename(columns={\"14 period EMV.\": '14 period EMV'}, inplace=True)\n",
    "\n",
    "    # Also calculate moving averages for features\n",
    "    data['ema50'] = data['close'] / data['close'].ewm(50).mean()\n",
    "    data['ema21'] = data['close'] / data['close'].ewm(21).mean()\n",
    "    data['ema15'] = data['close'] / data['close'].ewm(14).mean()\n",
    "    data['ema5'] = data['close'] / data['close'].ewm(5).mean()\n",
    "\n",
    "    # Instead of using the actual volume value (which changes over time), we normalize it with a moving volume average\n",
    "    data['normVol'] = data['volume'] / data['volume'].ewm(5).mean()\n",
    "\n",
    "    # Remove columns that won't be used as features\n",
    "    del (data['open'])\n",
    "    del (data['high'])\n",
    "    del (data['low'])\n",
    "    del (data['volume'])\n",
    "    del (data['Adj Close'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = _get_indicator_data(data)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_pred_data = data.iloc[-16:-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6867\n"
     ]
    }
   ],
   "source": [
    "def _produce_prediction(data, window):\n",
    "    \"\"\"\n",
    "    Function that produces the 'truth' values\n",
    "    At a given row, it looks 'window' rows ahead to see if the price increased (1) or decreased (0)\n",
    "    :param window: number of days, or rows to look ahead to see what the price did\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction = (data.shift(-window)['close'] >= data['close'])\n",
    "    prediction = prediction.iloc[:-window]\n",
    "    data['pred'] = prediction.astype(int)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = _produce_prediction(data, window=15)\n",
    "del (data['close'])\n",
    "data = data.dropna() # Some indicators produce NaN values for the first few rows, we just remove them here\n",
    "data.tail()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime\n",
      "2020-09-01 12:31:00-04:00    0.0\n",
      "2020-09-01 12:32:00-04:00    0.0\n",
      "2020-09-01 12:33:00-04:00    0.0\n",
      "2020-09-01 12:34:00-04:00    1.0\n",
      "2020-09-01 12:35:00-04:00    1.0\n",
      "2020-09-01 12:36:00-04:00    0.0\n",
      "2020-09-01 12:37:00-04:00    0.0\n",
      "2020-09-01 12:38:00-04:00    0.0\n",
      "2020-09-01 12:39:00-04:00    0.0\n",
      "2020-09-01 12:40:00-04:00    0.0\n",
      "2020-09-01 12:41:00-04:00    0.0\n",
      "2020-09-01 12:42:00-04:00    0.0\n",
      "2020-09-01 12:43:00-04:00    1.0\n",
      "2020-09-01 12:44:00-04:00    0.0\n",
      "2020-09-01 12:45:00-04:00    1.0\n",
      "2020-09-01 12:46:00-04:00    1.0\n",
      "2020-09-01 12:47:00-04:00    1.0\n",
      "Name: pred, dtype: float64\n",
      "X Train : 1678\n",
      "X Test  : 17\n",
      "y Train : 1678\n",
      "y Test  : 17\n"
     ]
    }
   ],
   "source": [
    "def _split_data(data):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to partition the data into the train and test set\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    y = data['pred']\n",
    "    features = [x for x in data.columns if x not in ['pred']]\n",
    "    X = data[features]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size= 99 * len(X) // 100,shuffle=False)\n",
    "    print(y_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = _split_data(data)\n",
    "print('X Train : ' + str(len(X_train)))\n",
    "print('X Test  : ' + str(len(X_test)))\n",
    "print('y Train : ' + str(len(y_train)))\n",
    "print('y Test  : ' + str(len(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Next we create and train our random forest classifier\n",
    "\"\"\"\n",
    "\n",
    "def _train_random_forest(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    \"\"\"\n",
    "    Function that uses random forest classifier to train the model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new random forest classifier\n",
    "    rf = RandomForestClassifier()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    #params_rf = {'n_estimators': [110,130,140,150,160,180,200]}\n",
    "    \n",
    "    # Use gridsearch to test all values for n_estimators\n",
    "    #rf_gs = GridSearchCV(rf, params_rf, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    #rf_best = rf_gs.best_estimator_\n",
    "    \n",
    "    # Check best n_estimators value\n",
    "    #print(rf_gs.best_params_)\n",
    "    \n",
    "    prediction = rf.predict(X_test)\n",
    "\n",
    "#     print(classification_report(y_test, prediction))\n",
    "#     print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return rf\n",
    "    \n",
    "#rf_model = _train_random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_KNN(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    knn = KNeighborsClassifier()\n",
    "    # Create a dictionary of all values we want to test for n_neighbors\n",
    "    params_knn = {'n_neighbors': np.arange(1, 10)}\n",
    "    \n",
    "    # Use gridsearch to test all values for n_neighbors\n",
    "    #knn_gs = GridSearchCV(knn, params_knn, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    #knn_best = knn_gs.best_estimator_\n",
    "     \n",
    "    # Check best n_neigbors value\n",
    "    #print(knn_gs.best_params_)\n",
    "    \n",
    "#     prediction = knn.predict(X_test)\n",
    "\n",
    "#     print(classification_report(y_test, prediction))\n",
    "#     print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return knn\n",
    "    \n",
    "#knn_model = _train_KNN(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_GBT(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    clf = GradientBoostingClassifier()\n",
    "    \n",
    "    # Dictionary of parameters to optimize\n",
    "    #params_gbt = {'n_estimators' :[150,160,170,180] , 'learning_rate' :[0.2,0.1,0.09] }\n",
    "    \n",
    "    # Use gridsearch to test all values for n_neighbors\n",
    "    #grid_search = GridSearchCV(clf, params_gbt, cv=5)\n",
    "    \n",
    "    # Fit model to training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #gbt_best = grid_search.best_estimator_\n",
    "    \n",
    "    # Save best model\n",
    "    #print(grid_search.best_params_)\n",
    "    \n",
    "    prediction = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    \n",
    "    return clf\n",
    "\n",
    "\n",
    "#gbt_model = _train_GBT(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensemble_model(rf_model, knn_model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Create a dictionary of our models\n",
    "    estimators=[('knn', knn_model), ('rf', rf_model)]\n",
    "    \n",
    "    # Create our voting classifier, inputting our models\n",
    "    ensemble = VotingClassifier(estimators, voting='soft')\n",
    "    \n",
    "    #fit model to training data\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    \n",
    "    #test our model on the test data\n",
    "    print(ensemble.score(X_test, y_test))\n",
    "    \n",
    "    prediction = ensemble.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return ensemble\n",
    "    \n",
    "#ensemble_model = _ensemble_model(rf_model, knn_model, gbt_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.67      0.53         6\n",
      "         1.0       0.33      0.17      0.22         6\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.39      0.42      0.38        12\n",
      "weighted avg       0.39      0.42      0.38        12\n",
      "\n",
      "[[4 2]\n",
      " [5 1]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.4166666666666667 0.4166666666666667\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80         3\n",
      "         1.0       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.95      0.83      0.87        12\n",
      "weighted avg       0.92      0.92      0.91        12\n",
      "\n",
      "[[2 1]\n",
      " [0 9]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "1.0 0.75 0.9166666666666666\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.75      0.86        12\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.50      0.38      0.43        12\n",
      "weighted avg       1.00      0.75      0.86        12\n",
      "\n",
      "[[0 0]\n",
      " [3 9]]\n",
      "rf prediction is  [0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 1.0 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.08      1.00      0.15         1\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.04      0.50      0.08        12\n",
      "weighted avg       0.01      0.08      0.01        12\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0  1]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "0.08333333333333333 0.08333333333333333 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.80      0.73         5\n",
      "         1.0       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.75      0.76      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "[[4 1]\n",
      " [2 5]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.5 0.75\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.75 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.17      0.29         6\n",
      "         1.0       0.55      1.00      0.71         6\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.77      0.58      0.50        12\n",
      "weighted avg       0.77      0.58      0.50        12\n",
      "\n",
      "[[1 5]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "1.0 0.5833333333333334 0.5833333333333334\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      1.00      0.71         5\n",
      "         1.0       1.00      0.43      0.60         7\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.78      0.71      0.66        12\n",
      "weighted avg       0.81      0.67      0.65        12\n",
      "\n",
      "[[5 0]\n",
      " [4 3]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "0.9166666666666666 0.4166666666666667 0.6666666666666666\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.17      0.29        12\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.50      0.08      0.14        12\n",
      "weighted avg       1.00      0.17      0.29        12\n",
      "\n",
      "[[ 0  0]\n",
      " [10  2]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.75 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        10\n",
      "         1.0       0.17      1.00      0.29         2\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0  2]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.4166666666666667 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.42      0.59        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.50      0.21      0.29        12\n",
      "weighted avg       1.00      0.42      0.59        12\n",
      "\n",
      "[[5 7]\n",
      " [0 0]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.25 0.5833333333333334 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.36      0.53        11\n",
      "         1.0       0.12      1.00      0.22         1\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.56      0.68      0.38        12\n",
      "weighted avg       0.93      0.42      0.51        12\n",
      "\n",
      "[[4 7]\n",
      " [0 1]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.4166666666666667 0.4166666666666667\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.73      0.80        11\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.44      0.36      0.40        12\n",
      "weighted avg       0.81      0.67      0.73        12\n",
      "\n",
      "[[8 3]\n",
      " [1 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.6666666666666666 0.8333333333333334 0.6666666666666666\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      1.00      0.29         2\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 2  0]\n",
      " [10  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.16666666666666666 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.50      0.29      0.37        12\n",
      "weighted avg       1.00      0.58      0.74        12\n",
      "\n",
      "[[0 0]\n",
      " [5 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.6666666666666666 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      1.00      0.94         8\n",
      "         1.0       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.94      0.88      0.90        12\n",
      "weighted avg       0.93      0.92      0.91        12\n",
      "\n",
      "[[8 0]\n",
      " [1 3]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.9166666666666666 0.9166666666666666\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.9166666666666666 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         9\n",
      "         1.0       0.25      1.00      0.40         3\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[0 9]\n",
      " [0 3]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.25 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.70      0.82        10\n",
      "         1.0       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.70      0.85      0.70        12\n",
      "weighted avg       0.90      0.75      0.78        12\n",
      "\n",
      "[[7 3]\n",
      " [0 2]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.8333333333333334 0.75 0.75\n",
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         8\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[8 0]\n",
      " [4 0]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.08333333333333333 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.0 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.9166666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         9\n",
      "         1.0       0.25      1.00      0.40         3\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[0 9]\n",
      " [0 3]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.25 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.91        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.50      0.42      0.45        12\n",
      "weighted avg       1.00      0.83      0.91        12\n",
      "\n",
      "[[10  2]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.25 0.9166666666666666 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.50      0.67        12\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.25      0.33        12\n",
      "weighted avg       1.00      0.50      0.67        12\n",
      "\n",
      "[[0 0]\n",
      " [6 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.16666666666666666 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.27      1.00      0.43         3\n",
      "         1.0       1.00      0.11      0.20         9\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.64      0.56      0.31        12\n",
      "weighted avg       0.82      0.33      0.26        12\n",
      "\n",
      "[[3 0]\n",
      " [8 1]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.6666666666666666 0.25 0.3333333333333333\n",
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      1.00      0.62         5\n",
      "         1.0       1.00      0.14      0.25         7\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.73      0.57      0.44        12\n",
      "weighted avg       0.77      0.50      0.41        12\n",
      "\n",
      "[[5 0]\n",
      " [6 1]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "0.5 0.5 0.5\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      1.00      0.75         6\n",
      "         1.0       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.80      0.67      0.62        12\n",
      "weighted avg       0.80      0.67      0.62        12\n",
      "\n",
      "[[6 0]\n",
      " [4 2]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.5 0.6666666666666666\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95         9\n",
      "         1.0       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.95      0.83      0.87        12\n",
      "weighted avg       0.92      0.92      0.91        12\n",
      "\n",
      "[[9 0]\n",
      " [1 2]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.]\n",
      "0.9166666666666666 0.75 0.9166666666666666\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.89      0.73      0.80        11\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.44      0.36      0.40        12\n",
      "weighted avg       0.81      0.67      0.73        12\n",
      "\n",
      "[[0 1]\n",
      " [3 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "0.75 0.5 0.6666666666666666\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.16666666666666666 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      1.00      0.40         2\n",
      "         1.0       1.00      0.40      0.57        10\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.62      0.70      0.49        12\n",
      "weighted avg       0.88      0.50      0.54        12\n",
      "\n",
      "[[2 0]\n",
      " [6 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5\n",
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67        10\n",
      "         1.0       0.29      1.00      0.44         2\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.64      0.75      0.56        12\n",
      "weighted avg       0.88      0.58      0.63        12\n",
      "\n",
      "[[5 5]\n",
      " [0 2]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.50      0.29      0.37        12\n",
      "weighted avg       1.00      0.58      0.74        12\n",
      "\n",
      "[[0 0]\n",
      " [5 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.4166666666666667 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.75 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         9\n",
      "         1.0       0.25      1.00      0.40         3\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[0 9]\n",
      " [0 3]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "0.75 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67         2\n",
      "         1.0       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.95      0.75      0.81        12\n",
      "weighted avg       0.92      0.92      0.90        12\n",
      "\n",
      "[[ 1  1]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "ensemble prediction is  [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.9166666666666666 0.9166666666666666\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.67      0.80        12\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "[[0 0]\n",
      " [4 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         8\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[8 0]\n",
      " [4 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.17      0.29        12\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.50      0.08      0.14        12\n",
      "weighted avg       1.00      0.17      0.29        12\n",
      "\n",
      "[[ 0  0]\n",
      " [10  2]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.16666666666666666 0.0 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.08      0.15        12\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.50      0.04      0.08        12\n",
      "weighted avg       1.00      0.08      0.15        12\n",
      "\n",
      "[[ 0  0]\n",
      " [11  1]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 0.08333333333333333 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.17      0.29        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.50      0.08      0.14        12\n",
      "weighted avg       1.00      0.17      0.29        12\n",
      "\n",
      "[[ 2 10]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.4166666666666667 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         9\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[9 0]\n",
      " [3 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.8333333333333334 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67         6\n",
      "         1.0       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.83      0.75      0.73        12\n",
      "weighted avg       0.83      0.75      0.73        12\n",
      "\n",
      "[[3 3]\n",
      " [0 6]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "truth values are  [0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.8333333333333334 0.75\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.67      0.80        12\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "[[0 0]\n",
      " [4 8]]\n",
      "rf prediction is  [1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 1.0 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.12      0.22         8\n",
      "         1.0       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.68      0.56      0.38        12\n",
      "weighted avg       0.79      0.42      0.33        12\n",
      "\n",
      "[[1 7]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.9166666666666666 0.4166666666666667\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90        10\n",
      "         1.0       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.70      0.70      0.70        12\n",
      "weighted avg       0.83      0.83      0.83        12\n",
      "\n",
      "[[9 1]\n",
      " [1 1]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.75 0.75 0.8333333333333334\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      1.00      0.71         6\n",
      "         1.0       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.77      0.58      0.50        12\n",
      "weighted avg       0.77      0.58      0.50        12\n",
      "\n",
      "[[6 0]\n",
      " [5 1]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      "0.5 0.5 0.5833333333333334\n",
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.75 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95        10\n",
      "         1.0       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.83      0.95      0.87        12\n",
      "weighted avg       0.94      0.92      0.92        12\n",
      "\n",
      "[[9 1]\n",
      " [0 2]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "0.25 1.0 0.9166666666666666\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.62      0.77         8\n",
      "         1.0       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.79      0.81      0.75        12\n",
      "weighted avg       0.86      0.75      0.76        12\n",
      "\n",
      "[[5 3]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 0.3333333333333333 0.75\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.42      0.59        12\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.50      0.21      0.29        12\n",
      "weighted avg       1.00      0.42      0.59        12\n",
      "\n",
      "[[0 0]\n",
      " [7 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.0 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1.]\n",
      "0.75 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.75 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.08      0.15        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.50      0.04      0.08        12\n",
      "weighted avg       1.00      0.08      0.15        12\n",
      "\n",
      "[[ 1 11]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.08333333333333333 0.0 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[10  0]\n",
      " [ 2  0]]\n",
      "rf prediction is  [0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      1.00      0.29         2\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 2  0]\n",
      " [10  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "0.16666666666666666 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.50      0.29      0.37        12\n",
      "weighted avg       1.00      0.58      0.74        12\n",
      "\n",
      "[[0 0]\n",
      " [5 7]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 1.0 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.75 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.50      0.29      0.37        12\n",
      "weighted avg       1.00      0.58      0.74        12\n",
      "\n",
      "[[0 0]\n",
      " [5 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.5 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        10\n",
      "         1.0       0.17      1.00      0.29         2\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0  2]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        11\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.8333333333333334 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.67      0.36         3\n",
      "         1.0       0.75      0.33      0.46         9\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.50      0.50      0.41        12\n",
      "weighted avg       0.62      0.42      0.44        12\n",
      "\n",
      "[[2 1]\n",
      " [6 3]]\n",
      "rf prediction is  [1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.6666666666666666 0.4166666666666667\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.8333333333333334 0.16666666666666666 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.08      1.00      0.15         1\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.04      0.50      0.08        12\n",
      "weighted avg       0.01      0.08      0.01        12\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0  1]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.08333333333333333 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.9166666666666666 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         9\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[9 0]\n",
      " [3 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "0.8333333333333334 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.82      0.86        11\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.45      0.41      0.43        12\n",
      "weighted avg       0.83      0.75      0.79        12\n",
      "\n",
      "[[9 2]\n",
      " [1 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.75 0.9166666666666666 0.75\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      1.00      0.29         2\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 2  0]\n",
      " [10  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.16666666666666666 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         9\n",
      "         1.0       0.25      1.00      0.40         3\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[0 9]\n",
      " [0 3]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "0.75 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         1\n",
      "         1.0       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.67      0.91      0.70        12\n",
      "weighted avg       0.94      0.83      0.87        12\n",
      "\n",
      "[[1 0]\n",
      " [2 9]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.08333333333333333 0.8333333333333334\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50         9\n",
      "         1.0       0.33      1.00      0.50         3\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.67      0.67      0.50        12\n",
      "weighted avg       0.83      0.50      0.50        12\n",
      "\n",
      "[[3 6]\n",
      " [0 3]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "truth values are  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.25 0.5\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         4\n",
      "         1.0       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.83      0.88      0.83        12\n",
      "weighted avg       0.89      0.83      0.84        12\n",
      "\n",
      "[[4 0]\n",
      " [2 6]]\n",
      "rf prediction is  [0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.67      0.80        12\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "[[0 0]\n",
      " [4 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.4166666666666667 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.12      0.22         8\n",
      "         1.0       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.68      0.56      0.38        12\n",
      "weighted avg       0.79      0.42      0.33        12\n",
      "\n",
      "[[1 7]\n",
      " [0 4]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.3333333333333333 0.4166666666666667\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.4166666666666667 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         9\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[9 0]\n",
      " [3 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      1.00      0.40         3\n",
      "         1.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[3 0]\n",
      " [9 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "0.25 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[10  0]\n",
      " [ 2  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         9\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[9 0]\n",
      " [3 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "0.9166666666666666 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.45      0.62        11\n",
      "         1.0       0.14      1.00      0.25         1\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.57      0.73      0.44        12\n",
      "weighted avg       0.93      0.50      0.59        12\n",
      "\n",
      "[[5 6]\n",
      " [0 1]]\n",
      "rf prediction is  [1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 0.9166666666666666 0.5\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         8\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[8 0]\n",
      " [4 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.08      0.15        12\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.50      0.04      0.08        12\n",
      "weighted avg       1.00      0.08      0.15        12\n",
      "\n",
      "[[ 0  0]\n",
      " [11  1]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.08333333333333333 0.0 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.16666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.75 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         9\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[9 0]\n",
      " [3 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        11\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.64      0.78        11\n",
      "         1.0       0.20      1.00      0.33         1\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.60      0.82      0.56        12\n",
      "weighted avg       0.93      0.67      0.74        12\n",
      "\n",
      "[[7 4]\n",
      " [0 1]]\n",
      "rf prediction is  [1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.5833333333333334 0.6666666666666666\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[10  0]\n",
      " [ 2  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "0.4166666666666667 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      "0.75 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.20      0.33         5\n",
      "         1.0       0.64      1.00      0.78         7\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.82      0.60      0.56        12\n",
      "weighted avg       0.79      0.67      0.59        12\n",
      "\n",
      "[[1 4]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
      "0.6666666666666666 0.75 0.6666666666666666\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.75 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.75 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 0.9166666666666666 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      1.00      0.40         3\n",
      "         1.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[3 0]\n",
      " [9 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.25 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.45      0.62        11\n",
      "         1.0       0.14      1.00      0.25         1\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.57      0.73      0.44        12\n",
      "weighted avg       0.93      0.50      0.59        12\n",
      "\n",
      "[[5 6]\n",
      " [0 1]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 0.4166666666666667 0.5\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[10  0]\n",
      " [ 2  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.75      0.86        12\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.50      0.38      0.43        12\n",
      "weighted avg       1.00      0.75      0.86        12\n",
      "\n",
      "[[0 0]\n",
      " [3 9]]\n",
      "rf prediction is  [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.25      0.40        12\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.50      0.12      0.20        12\n",
      "weighted avg       1.00      0.25      0.40        12\n",
      "\n",
      "[[0 0]\n",
      " [9 3]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.0 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      1.00      0.29         2\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 2  0]\n",
      " [10  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.16666666666666666 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.75 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.73      0.84        11\n",
      "         1.0       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.62      0.86      0.62        12\n",
      "weighted avg       0.94      0.75      0.81        12\n",
      "\n",
      "[[8 3]\n",
      " [0 1]]\n",
      "rf prediction is  [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.16666666666666666 0.6666666666666666 0.75\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         8\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[8 0]\n",
      " [4 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.08      1.00      0.15         1\n",
      "         1.0       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.04      0.50      0.08        12\n",
      "weighted avg       0.01      0.08      0.01        12\n",
      "\n",
      "[[ 1  0]\n",
      " [11  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.08333333333333333 0.08333333333333333 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         1\n",
      "         1.0       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.75      0.95      0.81        12\n",
      "weighted avg       0.96      0.92      0.93        12\n",
      "\n",
      "[[ 1  0]\n",
      " [ 1 10]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.9166666666666666 0.9166666666666666\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        10\n",
      "         1.0       0.17      1.00      0.29         2\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0  2]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "0.16666666666666666 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.75      0.75         4\n",
      "         1.0       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.81      0.81      0.81        12\n",
      "weighted avg       0.83      0.83      0.83        12\n",
      "\n",
      "[[3 1]\n",
      " [1 7]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.8333333333333334 0.3333333333333333 0.8333333333333334\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        10\n",
      "         1.0       0.17      1.00      0.29         2\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0  2]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.16666666666666666 0.5 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.83      0.59         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.23      0.42      0.29        12\n",
      "weighted avg       0.23      0.42      0.29        12\n",
      "\n",
      "[[5 1]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "0.5 0.5 0.4166666666666667\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.42      0.59        12\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.50      0.21      0.29        12\n",
      "weighted avg       1.00      0.42      0.59        12\n",
      "\n",
      "[[0 0]\n",
      " [7 5]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "ensemble prediction is  [1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.16666666666666666 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.10      1.00      0.18         1\n",
      "         1.0       1.00      0.18      0.31        11\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.55      0.59      0.24        12\n",
      "weighted avg       0.92      0.25      0.30        12\n",
      "\n",
      "[[1 0]\n",
      " [9 2]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.16666666666666666 0.25\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.8333333333333334 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.80      0.67         5\n",
      "         1.0       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.69      0.69      0.67        12\n",
      "weighted avg       0.70      0.67      0.67        12\n",
      "\n",
      "[[4 1]\n",
      " [3 4]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.6666666666666666 0.6666666666666666\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.14      1.00      0.25         1\n",
      "         1.0       1.00      0.45      0.62        11\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.57      0.73      0.44        12\n",
      "weighted avg       0.93      0.50      0.59        12\n",
      "\n",
      "[[1 0]\n",
      " [6 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "knn prediction is  [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.8333333333333334 0.25 0.5\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        11\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      1.00      0.53         4\n",
      "         1.0       1.00      0.12      0.22         8\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.68      0.56      0.38        12\n",
      "weighted avg       0.79      0.42      0.33        12\n",
      "\n",
      "[[4 0]\n",
      " [7 1]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.3333333333333333 0.4166666666666667\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.0 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         7\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[7 0]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 0.4166666666666667 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.42      0.59        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.50      0.21      0.29        12\n",
      "weighted avg       1.00      0.42      0.59        12\n",
      "\n",
      "[[5 7]\n",
      " [0 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.3333333333333333 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59         5\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[5 0]\n",
      " [7 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.25      0.40        12\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.50      0.12      0.20        12\n",
      "weighted avg       1.00      0.25      0.40        12\n",
      "\n",
      "[[0 0]\n",
      " [9 3]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.3333333333333333 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "0.3333333333333333 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.60      0.71        10\n",
      "         1.0       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.53      0.55      0.50        12\n",
      "weighted avg       0.75      0.58      0.64        12\n",
      "\n",
      "[[6 4]\n",
      " [1 1]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "ensemble prediction is  [0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      "truth values are  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.4166666666666667 0.4166666666666667 0.5833333333333334\n",
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.08      1.00      0.15         1\n",
      "         1.0       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.04      0.50      0.08        12\n",
      "weighted avg       0.01      0.08      0.01        12\n",
      "\n",
      "[[ 1  0]\n",
      " [11  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.08333333333333333 0.08333333333333333 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "knn prediction is  [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.16666666666666666 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "0.75 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.08333333333333333 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.33      0.44         6\n",
      "         1.0       0.56      0.83      0.67         6\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.61      0.58      0.56        12\n",
      "weighted avg       0.61      0.58      0.56        12\n",
      "\n",
      "[[2 4]\n",
      " [1 5]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "knn prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "ensemble prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.50      0.29      0.37        12\n",
      "weighted avg       1.00      0.58      0.74        12\n",
      "\n",
      "[[0 0]\n",
      " [5 7]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 0.75 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "[[8 4]\n",
      " [0 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.75 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.10      0.18        10\n",
      "         1.0       0.18      1.00      0.31         2\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.59      0.55      0.24        12\n",
      "weighted avg       0.86      0.25      0.20        12\n",
      "\n",
      "[[1 9]\n",
      " [0 2]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.3333333333333333 0.25 0.25\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.80      0.80        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.40      0.40      0.40        12\n",
      "weighted avg       0.67      0.67      0.67        12\n",
      "\n",
      "[[8 2]\n",
      " [2 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.9166666666666666 0.6666666666666666 0.6666666666666666\n",
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.17      0.29        12\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.50      0.08      0.14        12\n",
      "weighted avg       1.00      0.17      0.29        12\n",
      "\n",
      "[[ 0  0]\n",
      " [10  2]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.16666666666666666 0.0 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[0 8]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.20      0.18         5\n",
      "         1.0       0.33      0.29      0.31         7\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.25      0.24      0.24        12\n",
      "weighted avg       0.26      0.25      0.26        12\n",
      "\n",
      "[[1 4]\n",
      " [5 2]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.6666666666666666 0.25\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.08      1.00      0.15         1\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.04      0.50      0.08        12\n",
      "weighted avg       0.01      0.08      0.01        12\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0  1]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 0.08333333333333333 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.67      0.73         6\n",
      "         1.0       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "[[4 2]\n",
      " [1 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.75 0.75\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         5\n",
      "         1.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[5 0]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.25      0.33        12\n",
      "weighted avg       1.00      0.50      0.67        12\n",
      "\n",
      "[[6 6]\n",
      " [0 0]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.4166666666666667 0.6666666666666666 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      1.00      0.57         4\n",
      "         1.0       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.70      0.62      0.49        12\n",
      "weighted avg       0.80      0.50      0.46        12\n",
      "\n",
      "[[4 0]\n",
      " [6 2]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.75 0.3333333333333333 0.5\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.42      0.59        12\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.50      0.21      0.29        12\n",
      "weighted avg       1.00      0.42      0.59        12\n",
      "\n",
      "[[0 0]\n",
      " [7 5]]\n",
      "rf prediction is  [1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.25      0.40        12\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.50      0.12      0.20        12\n",
      "weighted avg       1.00      0.25      0.40        12\n",
      "\n",
      "[[0 0]\n",
      " [9 3]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.17      0.22         6\n",
      "         1.0       0.44      0.67      0.53         6\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.39      0.42      0.38        12\n",
      "weighted avg       0.39      0.42      0.38        12\n",
      "\n",
      "[[1 5]\n",
      " [2 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "truth values are  [1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.5 0.3333333333333333 0.4166666666666667\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.0 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50         6\n",
      "         1.0       0.60      1.00      0.75         6\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.80      0.67      0.62        12\n",
      "weighted avg       0.80      0.67      0.62        12\n",
      "\n",
      "[[2 4]\n",
      " [0 6]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.4166666666666667 0.6666666666666666\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.6666666666666666 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.70      0.78      0.74         9\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.35      0.39      0.37        12\n",
      "weighted avg       0.53      0.58      0.55        12\n",
      "\n",
      "[[0 3]\n",
      " [2 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "truth values are  [1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.75 0.5833333333333334\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.67      0.80        12\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "[[0 0]\n",
      " [4 8]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.8333333333333334 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.20      0.33         5\n",
      "         1.0       0.64      1.00      0.78         7\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.82      0.60      0.56        12\n",
      "weighted avg       0.79      0.67      0.59        12\n",
      "\n",
      "[[1 4]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.75 0.6666666666666666\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 0.9166666666666666 1.0\n",
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.25      0.40        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.50      0.12      0.20        12\n",
      "weighted avg       1.00      0.25      0.40        12\n",
      "\n",
      "[[3 9]\n",
      " [0 0]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.16666666666666666 0.4166666666666667 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[10  0]\n",
      " [ 2  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.8333333333333334 0.6666666666666666 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      1.00      0.29         2\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 2  0]\n",
      " [10  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.16666666666666666 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[0 8]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.5 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 0.25 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.50      0.29      0.37        12\n",
      "weighted avg       1.00      0.58      0.74        12\n",
      "\n",
      "[[0 0]\n",
      " [5 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.6666666666666666 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.5 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.50      0.42      0.45        12\n",
      "weighted avg       1.00      0.83      0.91        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 2 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.5833333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.91      0.95        11\n",
      "         1.0       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.75      0.95      0.81        12\n",
      "weighted avg       0.96      0.92      0.93        12\n",
      "\n",
      "[[10  1]\n",
      " [ 0  1]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.8333333333333334 0.9166666666666666 0.9166666666666666\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.14      1.00      0.25         1\n",
      "         1.0       1.00      0.45      0.62        11\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.57      0.73      0.44        12\n",
      "weighted avg       0.93      0.50      0.59        12\n",
      "\n",
      "[[1 0]\n",
      " [6 5]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.3333333333333333 0.5\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         9\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[9 0]\n",
      " [3 0]]\n",
      "rf prediction is  [0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.27      0.75      0.40         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.14      0.38      0.20        12\n",
      "weighted avg       0.09      0.25      0.13        12\n",
      "\n",
      "[[3 1]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "0.3333333333333333 0.25 0.25\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         4\n",
      "         1.0       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[4 0]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "1.0 0.6666666666666666 1.0\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "[[8 4]\n",
      " [0 0]]\n",
      "rf prediction is  [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 0.0 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.60      0.67        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.38      0.30      0.33        12\n",
      "weighted avg       0.62      0.50      0.56        12\n",
      "\n",
      "[[6 4]\n",
      " [2 0]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.3333333333333333 0.75 0.5\n",
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      1.00      0.40         3\n",
      "         1.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[3 0]\n",
      " [9 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 1.0 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.3333333333333333 1.0 1.0\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         8\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[8 0]\n",
      " [4 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.50      0.57         4\n",
      "         1.0       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.72      0.69      0.70        12\n",
      "weighted avg       0.74      0.75      0.74        12\n",
      "\n",
      "[[2 2]\n",
      " [1 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      "0.75 0.6666666666666666 0.75\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.82      0.90        11\n",
      "         1.0       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.67      0.91      0.70        12\n",
      "weighted avg       0.94      0.83      0.87        12\n",
      "\n",
      "[[9 2]\n",
      " [0 1]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 0.08333333333333333 0.8333333333333334\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         2\n",
      "         1.0       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.75      0.90      0.78        12\n",
      "weighted avg       0.92      0.83      0.85        12\n",
      "\n",
      "[[2 0]\n",
      " [2 8]]\n",
      "rf prediction is  [1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "0.5833333333333334 0.8333333333333334 0.8333333333333334\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.09      1.00      0.17         1\n",
      "         1.0       1.00      0.09      0.17        11\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.55      0.55      0.17        12\n",
      "weighted avg       0.92      0.17      0.17        12\n",
      "\n",
      "[[ 1  0]\n",
      " [10  1]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.08333333333333333 0.9166666666666666 0.16666666666666666\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.70      0.78        10\n",
      "         1.0       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.56      0.60      0.56        12\n",
      "weighted avg       0.77      0.67      0.70        12\n",
      "\n",
      "[[7 3]\n",
      " [1 1]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "truth values are  [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.8333333333333334 0.6666666666666666\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[11  1]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.16666666666666666 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.91        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.50      0.42      0.45        12\n",
      "weighted avg       1.00      0.83      0.91        12\n",
      "\n",
      "[[10  2]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 1.0 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[10  0]\n",
      " [ 2  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "0.6666666666666666 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        11\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59         5\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[5 0]\n",
      " [7 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.4166666666666667 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.14      0.22         7\n",
      "         1.0       0.40      0.80      0.53         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.45      0.47      0.38        12\n",
      "weighted avg       0.46      0.42      0.35        12\n",
      "\n",
      "[[1 6]\n",
      " [1 4]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.4166666666666667 0.4166666666666667\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        10\n",
      "         1.0       0.17      1.00      0.29         2\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0  2]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 1.0 1.0\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      1.00      0.29         2\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 2  0]\n",
      " [10  0]]\n",
      "rf prediction is  [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.08333333333333333 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59         5\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[5 0]\n",
      " [7 0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.50      0.42      0.45        12\n",
      "weighted avg       1.00      0.83      0.91        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 2 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.4166666666666667 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 1.0 1.0\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.73      0.89      0.80         9\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.36      0.44      0.40        12\n",
      "weighted avg       0.55      0.67      0.60        12\n",
      "\n",
      "[[0 3]\n",
      " [1 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.3333333333333333 0.6666666666666666\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50         9\n",
      "         1.0       0.33      1.00      0.50         3\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.67      0.67      0.50        12\n",
      "weighted avg       0.83      0.50      0.50        12\n",
      "\n",
      "[[3 6]\n",
      " [0 3]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "0.5833333333333334 0.25 0.5\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.08333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         3\n",
      "         1.0       1.00      0.33      0.50         9\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.67      0.67      0.50        12\n",
      "weighted avg       0.83      0.50      0.50        12\n",
      "\n",
      "[[3 0]\n",
      " [6 3]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "0.5833333333333334 0.6666666666666666 0.5\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.16666666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67         4\n",
      "         1.0       0.80      1.00      0.89         8\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.90      0.75      0.78        12\n",
      "weighted avg       0.87      0.83      0.81        12\n",
      "\n",
      "[[2 2]\n",
      " [0 8]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.6666666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.50      0.42      0.45        12\n",
      "weighted avg       1.00      0.83      0.91        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 2 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 1.0 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.25      0.33        12\n",
      "weighted avg       1.00      0.50      0.67        12\n",
      "\n",
      "[[6 6]\n",
      " [0 0]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.25 0.9166666666666666 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59         5\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[5 0]\n",
      " [7 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[0 8]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.4166666666666667 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[10  0]\n",
      " [ 2  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.75      0.75         4\n",
      "         1.0       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.81      0.81      0.81        12\n",
      "weighted avg       0.83      0.83      0.83        12\n",
      "\n",
      "[[3 1]\n",
      " [1 7]]\n",
      "rf prediction is  [1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.6666666666666666 0.8333333333333334\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.91        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.50      0.42      0.45        12\n",
      "weighted avg       1.00      0.83      0.91        12\n",
      "\n",
      "[[10  2]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 0.0 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      1.00      0.40         3\n",
      "         1.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[3 0]\n",
      " [9 0]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.75 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.42      0.59        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.50      0.21      0.29        12\n",
      "weighted avg       1.00      0.42      0.59        12\n",
      "\n",
      "[[5 7]\n",
      " [0 0]]\n",
      "rf prediction is  [0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.25 1.0 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "0.8333333333333334 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.9166666666666666 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.25 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         9\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[9 0]\n",
      " [3 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.08333333333333333 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         4\n",
      "         1.0       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.83      0.88      0.83        12\n",
      "weighted avg       0.89      0.83      0.84        12\n",
      "\n",
      "[[4 0]\n",
      " [2 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.75 0.8333333333333334 0.8333333333333334\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.17      0.29        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.50      0.08      0.14        12\n",
      "weighted avg       1.00      0.17      0.29        12\n",
      "\n",
      "[[ 2 10]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.0 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        11\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.5 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      "0.25 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      1.00      0.62         5\n",
      "         1.0       1.00      0.14      0.25         7\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.73      0.57      0.44        12\n",
      "weighted avg       0.77      0.50      0.41        12\n",
      "\n",
      "[[5 0]\n",
      " [6 1]]\n",
      "rf prediction is  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.4166666666666667 0.5\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      1.00      0.29         2\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 2  0]\n",
      " [10  0]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 1.0 1.0\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         9\n",
      "         1.0       0.25      1.00      0.40         3\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[0 9]\n",
      " [0 3]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
      "0.25 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.50      0.67        12\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.25      0.33        12\n",
      "weighted avg       1.00      0.50      0.67        12\n",
      "\n",
      "[[0 0]\n",
      " [6 6]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.0 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         9\n",
      "         1.0       0.25      1.00      0.40         3\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[0 9]\n",
      " [0 3]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.25 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         8\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[8 0]\n",
      " [4 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.4166666666666667 0.5833333333333334 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.75      0.86        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.50      0.38      0.43        12\n",
      "weighted avg       1.00      0.75      0.86        12\n",
      "\n",
      "[[9 3]\n",
      " [0 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.6666666666666666 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "0.5 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "0.5833333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "0.75 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         1\n",
      "         1.0       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[ 1  0]\n",
      " [ 0 11]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "knn prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[0 8]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.36      0.53        11\n",
      "         1.0       0.12      1.00      0.22         1\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.56      0.68      0.38        12\n",
      "weighted avg       0.93      0.42      0.51        12\n",
      "\n",
      "[[4 7]\n",
      " [0 1]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.08333333333333333 0.75 0.4166666666666667\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "[[8 4]\n",
      " [0 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 0.5 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.67      0.80        12\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "[[0 0]\n",
      " [4 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.39      0.35      0.37        12\n",
      "weighted avg       0.65      0.58      0.61        12\n",
      "\n",
      "[[0 2]\n",
      " [3 7]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.8333333333333334 0.5833333333333334\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 1.0 1.0\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[0 8]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.08333333333333333 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.12      1.00      0.22         1\n",
      "         1.0       1.00      0.36      0.53        11\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.56      0.68      0.38        12\n",
      "weighted avg       0.93      0.42      0.51        12\n",
      "\n",
      "[[1 0]\n",
      " [7 4]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.3333333333333333 0.9166666666666666 0.4166666666666667\n",
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         9\n",
      "         1.0       0.25      1.00      0.40         3\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[0 9]\n",
      " [0 3]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.25 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        10\n",
      "         1.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[10  0]\n",
      " [ 0  2]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.50      0.29      0.37        12\n",
      "weighted avg       1.00      0.58      0.74        12\n",
      "\n",
      "[[0 0]\n",
      " [5 7]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.0 0.75 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         4\n",
      "         1.0       1.00      0.50      0.67         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.75      0.75      0.67        12\n",
      "weighted avg       0.83      0.67      0.67        12\n",
      "\n",
      "[[4 0]\n",
      " [4 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.6666666666666666 0.6666666666666666\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         6\n",
      "         1.0       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.88      0.83      0.83        12\n",
      "weighted avg       0.88      0.83      0.83        12\n",
      "\n",
      "[[6 0]\n",
      " [2 4]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 1.0 0.8333333333333334\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.5833333333333334 1.0\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.50      0.42      0.45        12\n",
      "weighted avg       1.00      0.83      0.91        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 2 10]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.16666666666666666 1.0 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         1\n",
      "         1.0       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[ 1  0]\n",
      " [ 0 11]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.5833333333333334 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.9166666666666666 1.0\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[0 8]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.20      0.33        10\n",
      "         1.0       0.20      1.00      0.33         2\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.60      0.60      0.33        12\n",
      "weighted avg       0.87      0.33      0.33        12\n",
      "\n",
      "[[2 8]\n",
      " [0 2]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "ensemble prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.3333333333333333 0.75 0.3333333333333333\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.25 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.75      0.86        12\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.50      0.38      0.43        12\n",
      "weighted avg       1.00      0.75      0.86        12\n",
      "\n",
      "[[0 0]\n",
      " [3 9]]\n",
      "rf prediction is  [1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 1.0 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "0.6666666666666666 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      1.00      0.84         8\n",
      "         1.0       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.86      0.62      0.62        12\n",
      "weighted avg       0.82      0.75      0.69        12\n",
      "\n",
      "[[8 0]\n",
      " [3 1]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.16666666666666666 0.6666666666666666 0.75\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      1.00      0.82         7\n",
      "         1.0       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.85      0.70      0.70        12\n",
      "weighted avg       0.82      0.75      0.72        12\n",
      "\n",
      "[[7 0]\n",
      " [3 2]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1.]\n",
      "0.8333333333333334 0.5833333333333334 0.75\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.17      0.29        12\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.50      0.08      0.14        12\n",
      "weighted avg       1.00      0.17      0.29        12\n",
      "\n",
      "[[ 0  0]\n",
      " [10  2]]\n",
      "rf prediction is  [0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.0 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         8\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[8 0]\n",
      " [4 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.75 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      1.00      0.44         2\n",
      "         1.0       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.64      0.75      0.56        12\n",
      "weighted avg       0.88      0.58      0.63        12\n",
      "\n",
      "[[2 0]\n",
      " [5 5]]\n",
      "rf prediction is  [1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "0.4166666666666667 0.5833333333333334 0.5833333333333334\n",
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.08      1.00      0.15         1\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.04      0.50      0.08        12\n",
      "weighted avg       0.01      0.08      0.01        12\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0  1]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.08333333333333333 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.6666666666666666 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.8333333333333334 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[10  0]\n",
      " [ 2  0]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "0.5833333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         3\n",
      "         1.0       1.00      0.33      0.50         9\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.67      0.67      0.50        12\n",
      "weighted avg       0.83      0.50      0.50        12\n",
      "\n",
      "[[3 0]\n",
      " [6 3]]\n",
      "rf prediction is  [1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.25 0.5\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         9\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[9 0]\n",
      " [3 0]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      1.00      0.29         2\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 2  0]\n",
      " [10  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      1.00      0.44         2\n",
      "         1.0       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.64      0.75      0.56        12\n",
      "weighted avg       0.88      0.58      0.63        12\n",
      "\n",
      "[[2 0]\n",
      " [5 5]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "0.5 0.8333333333333334 0.5833333333333334\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      1.00      0.33         1\n",
      "         1.0       1.00      0.64      0.78        11\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.60      0.82      0.56        12\n",
      "weighted avg       0.93      0.67      0.74        12\n",
      "\n",
      "[[1 0]\n",
      " [4 7]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5833333333333334 0.9166666666666666 0.6666666666666666\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        10\n",
      "         1.0       0.17      1.00      0.29         2\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0  2]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "0.5833333333333334 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.36      0.53        11\n",
      "         1.0       0.12      1.00      0.22         1\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.56      0.68      0.38        12\n",
      "weighted avg       0.93      0.42      0.51        12\n",
      "\n",
      "[[4 7]\n",
      " [0 1]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.08333333333333333 0.6666666666666666 0.4166666666666667\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         3\n",
      "         1.0       1.00      0.33      0.50         9\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.67      0.67      0.50        12\n",
      "weighted avg       0.83      0.50      0.50        12\n",
      "\n",
      "[[3 0]\n",
      " [6 3]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.25 0.5 0.5\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.22      0.36         9\n",
      "         1.0       0.30      1.00      0.46         3\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.65      0.61      0.41        12\n",
      "weighted avg       0.83      0.42      0.39        12\n",
      "\n",
      "[[2 7]\n",
      " [0 3]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "0.9166666666666666 0.25 0.4166666666666667\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[4 8]\n",
      " [0 0]]\n",
      "rf prediction is  [1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.16666666666666666 0.5 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         9\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[9 0]\n",
      " [3 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95        10\n",
      "         1.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.95      0.75      0.81        12\n",
      "weighted avg       0.92      0.92      0.90        12\n",
      "\n",
      "[[10  0]\n",
      " [ 1  1]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 0.8333333333333334 0.9166666666666666\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        10\n",
      "         1.0       0.17      1.00      0.29         2\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0  2]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "0.16666666666666666 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         6\n",
      "         1.0       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.83      0.75      0.73        12\n",
      "weighted avg       0.83      0.75      0.73        12\n",
      "\n",
      "[[6 0]\n",
      " [3 3]]\n",
      "rf prediction is  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.6666666666666666 0.5 0.75\n",
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.17      0.29        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.50      0.08      0.14        12\n",
      "weighted avg       1.00      0.17      0.29        12\n",
      "\n",
      "[[ 2 10]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.0 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.4166666666666667 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        11\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 1.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.08      0.15        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.50      0.04      0.08        12\n",
      "weighted avg       1.00      0.08      0.15        12\n",
      "\n",
      "[[ 1 11]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.3333333333333333 0.0 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      1.00      0.29         2\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 2  0]\n",
      " [10  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.16666666666666666 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         4\n",
      "         1.0       0.67      1.00      0.80         8\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[0 4]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "1.0 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.91      0.95        11\n",
      "         1.0       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.75      0.95      0.81        12\n",
      "weighted avg       0.96      0.92      0.93        12\n",
      "\n",
      "[[10  1]\n",
      " [ 0  1]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.9166666666666666 0.08333333333333333 0.9166666666666666\n",
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.08      1.00      0.15         1\n",
      "         1.0       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.04      0.50      0.08        12\n",
      "weighted avg       0.01      0.08      0.01        12\n",
      "\n",
      "[[ 1  0]\n",
      " [11  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.08333333333333333 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.0 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        10\n",
      "         1.0       0.17      1.00      0.29         2\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 0 10]\n",
      " [ 0  2]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.16666666666666666 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.25 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59         5\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[5 0]\n",
      " [7 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91        10\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[10  0]\n",
      " [ 2  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "0.5 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0  0]\n",
      " [12  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.08333333333333333 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.75      0.86        12\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.50      0.38      0.43        12\n",
      "weighted avg       1.00      0.75      0.86        12\n",
      "\n",
      "[[0 0]\n",
      " [3 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 1.0 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         1\n",
      "         1.0       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.67      0.91      0.70        12\n",
      "weighted avg       0.94      0.83      0.87        12\n",
      "\n",
      "[[1 0]\n",
      " [2 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "ensemble prediction is  [0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.16666666666666666 0.8333333333333334\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.6666666666666666 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         9\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[9 0]\n",
      " [3 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "0.5 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      1.00      0.29         2\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.08      0.50      0.14        12\n",
      "weighted avg       0.03      0.17      0.05        12\n",
      "\n",
      "[[ 2  0]\n",
      " [10  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 0.16666666666666666 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.9166666666666666 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.41      0.45      0.43        12\n",
      "weighted avg       0.68      0.75      0.71        12\n",
      "\n",
      "[[0 2]\n",
      " [1 9]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.16666666666666666 0.8333333333333334 0.75\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.42      1.00      0.59         5\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[0 7]\n",
      " [0 5]]\n",
      "rf prediction is  [1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         8\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[8 0]\n",
      " [4 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.50      0.46      0.48        12\n",
      "weighted avg       1.00      0.92      0.96        12\n",
      "\n",
      "[[ 0  0]\n",
      " [ 1 11]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.0 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.75      0.86         4\n",
      "         1.0       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.94      0.88      0.90        12\n",
      "weighted avg       0.93      0.92      0.91        12\n",
      "\n",
      "[[3 1]\n",
      " [0 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.9166666666666666\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80        12\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "[[8 4]\n",
      " [0 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 0.0 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.30      1.00      0.46         3\n",
      "         1.0       1.00      0.22      0.36         9\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.65      0.61      0.41        12\n",
      "weighted avg       0.83      0.42      0.39        12\n",
      "\n",
      "[[3 0]\n",
      " [7 2]]\n",
      "rf prediction is  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "truth values are  [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.3333333333333333 0.4166666666666667\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 0.75 1.0\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.50      0.17      0.25        12\n",
      "weighted avg       1.00      0.33      0.50        12\n",
      "\n",
      "[[0 0]\n",
      " [8 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.16666666666666666 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59         5\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[5 0]\n",
      " [7 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.3333333333333333 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80         8\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "[[8 0]\n",
      " [4 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.09      1.00      0.17         1\n",
      "         1.0       1.00      0.09      0.17        11\n",
      "\n",
      "    accuracy                           0.17        12\n",
      "   macro avg       0.55      0.55      0.17        12\n",
      "weighted avg       0.92      0.17      0.17        12\n",
      "\n",
      "[[ 1  0]\n",
      " [10  1]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "1.0 0.08333333333333333 0.16666666666666666\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[0 5]\n",
      " [0 7]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.16666666666666666 1.0 1.0\n",
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9166666666666666 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         3\n",
      "         1.0       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.38      0.50      0.43        12\n",
      "weighted avg       0.56      0.75      0.64        12\n",
      "\n",
      "[[0 3]\n",
      " [0 9]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "0.75 0.75 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      12.0\n",
      "   macro avg       0.00      0.00      0.00      12.0\n",
      "weighted avg       0.00      0.00      0.00      12.0\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  0]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.08      1.00      0.15         1\n",
      "\n",
      "    accuracy                           0.08        12\n",
      "   macro avg       0.04      0.50      0.08        12\n",
      "weighted avg       0.01      0.08      0.01        12\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0  1]]\n",
      "rf prediction is  [1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.75 0.08333333333333333 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      1.00      0.50         4\n",
      "         1.0       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[4 0]\n",
      " [8 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[0 8]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.5833333333333334 1.0 1.0\n",
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      1.00      0.74         7\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "[[7 0]\n",
      " [5 0]]\n",
      "rf prediction is  [0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.5833333333333334 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.67      0.80        12\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.50      0.33      0.40        12\n",
      "weighted avg       1.00      0.67      0.80        12\n",
      "\n",
      "[[0 0]\n",
      " [4 8]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.6666666666666666 1.0 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.75 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[0 8]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        11\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.46      0.50      0.48        12\n",
      "weighted avg       0.84      0.92      0.88        12\n",
      "\n",
      "[[11  0]\n",
      " [ 1  0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.8333333333333334 0.9166666666666666 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      1.00      0.40         3\n",
      "         1.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.12      0.50      0.20        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "[[3 0]\n",
      " [9 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 0.25 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.17      0.50      0.25        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n",
      "[[0 8]\n",
      " [0 4]]\n",
      "rf prediction is  [1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.8333333333333334 0.3333333333333333 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         6\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[6 0]\n",
      " [6 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.16666666666666666 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.08333333333333333 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0 1.0 1.0\n",
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59         5\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.42        12\n",
      "   macro avg       0.21      0.50      0.29        12\n",
      "weighted avg       0.17      0.42      0.25        12\n",
      "\n",
      "[[5 0]\n",
      " [7 0]]\n",
      "rf prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ensemble prediction is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "truth values are  [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.4166666666666667 0.4166666666666667 0.4166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.25 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.3333333333333333 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.42      0.50      0.45        12\n",
      "weighted avg       0.69      0.83      0.76        12\n",
      "\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "0.8333333333333334 0.8333333333333334 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.25      0.50      0.33        12\n",
      "weighted avg       0.25      0.50      0.33        12\n",
      "\n",
      "[[0 6]\n",
      " [0 6]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "0.5 0.5 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasrea/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "[[12]]\n",
      "rf prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "knn prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "ensemble prediction is  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "truth values are  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0 1.0 1.0\n",
      "RF Accuracy = 0.6732649071358748\n",
      "KNN Accuracy = 0.67460899315738\n",
      "Ensemble Accuracy = 0.6925708699902248\n"
     ]
    }
   ],
   "source": [
    "def cross_Validation(data):\n",
    "\n",
    "    # Split data into equal partitions of size len_train\n",
    "    \n",
    "    num_train = 10 # Increment of how many starting points (len(data) / num_train  =  number of train-test sets)\n",
    "    len_train = 40 # Length of each train-test set\n",
    "    \n",
    "    # Lists to store the results from each model\n",
    "    rf_RESULTS = []\n",
    "    knn_RESULTS = []\n",
    "    ensemble_RESULTS = []\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        \n",
    "        # Partition the data into chunks of size len_train every num_train days\n",
    "        df = data.iloc[i * num_train : (i * num_train) + len_train]\n",
    "        i += 1\n",
    "        #print(i * num_train, (i * num_train) + len_train)\n",
    "        \n",
    "        if len(df) < 40:\n",
    "            break\n",
    "        \n",
    "        y = df['pred']\n",
    "        features = [x for x in df.columns if x not in ['pred']]\n",
    "        X = df[features]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size= 7 * len(X) // 10,shuffle=False)\n",
    "        \n",
    "        rf_model = _train_random_forest(X_train, y_train, X_test, y_test)\n",
    "        knn_model = _train_KNN(X_train, y_train, X_test, y_test)\n",
    "        ensemble_model = _ensemble_model(rf_model, knn_model, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        rf_prediction = rf_model.predict(X_test)\n",
    "        knn_prediction = knn_model.predict(X_test)\n",
    "        ensemble_prediction = ensemble_model.predict(X_test)\n",
    "        \n",
    "        print('rf prediction is ', rf_prediction)\n",
    "        print('knn prediction is ', knn_prediction)\n",
    "        print('ensemble prediction is ', ensemble_prediction)\n",
    "        print('truth values are ', y_test.values)\n",
    "        \n",
    "        rf_accuracy = accuracy_score(y_test.values, rf_prediction)\n",
    "        knn_accuracy = accuracy_score(y_test.values, knn_prediction)\n",
    "        ensemble_accuracy = accuracy_score(y_test.values, ensemble_prediction)\n",
    "        \n",
    "        print(rf_accuracy, knn_accuracy, ensemble_accuracy)\n",
    "        rf_RESULTS.append(rf_accuracy)\n",
    "        knn_RESULTS.append(knn_accuracy)\n",
    "        ensemble_RESULTS.append(ensemble_accuracy)\n",
    "        \n",
    "        \n",
    "    print('RF Accuracy = ' + str( sum(rf_RESULTS) / len(rf_RESULTS)))\n",
    "    print('KNN Accuracy = ' + str( sum(knn_RESULTS) / len(knn_RESULTS)))\n",
    "    print('Ensemble Accuracy = ' + str( sum(ensemble_RESULTS) / len(ensemble_RESULTS)))\n",
    "    \n",
    "    \n",
    "cross_Validation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>SIGNAL</th>\n",
       "      <th>14 period STOCH %K</th>\n",
       "      <th>MFV</th>\n",
       "      <th>14 period ATR</th>\n",
       "      <th>MOM</th>\n",
       "      <th>14 period MFI</th>\n",
       "      <th>ROC</th>\n",
       "      <th>...</th>\n",
       "      <th>OBV_y</th>\n",
       "      <th>20 period CCI</th>\n",
       "      <th>14 period EMV</th>\n",
       "      <th>VIm</th>\n",
       "      <th>VIp</th>\n",
       "      <th>ema50</th>\n",
       "      <th>ema21</th>\n",
       "      <th>ema15</th>\n",
       "      <th>ema5</th>\n",
       "      <th>normVol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-11</th>\n",
       "      <td>333.588249</td>\n",
       "      <td>75.867466</td>\n",
       "      <td>5.257100</td>\n",
       "      <td>4.752840</td>\n",
       "      <td>80.771767</td>\n",
       "      <td>4.717004e+11</td>\n",
       "      <td>3.360907</td>\n",
       "      <td>11.852584</td>\n",
       "      <td>60.416619</td>\n",
       "      <td>3.605122</td>\n",
       "      <td>...</td>\n",
       "      <td>3.565331e+10</td>\n",
       "      <td>116.467862</td>\n",
       "      <td>18.717993</td>\n",
       "      <td>-7.971096</td>\n",
       "      <td>11.995666</td>\n",
       "      <td>1.079468</td>\n",
       "      <td>1.045866</td>\n",
       "      <td>1.031954</td>\n",
       "      <td>1.011003</td>\n",
       "      <td>1.110617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-12</th>\n",
       "      <td>336.091889</td>\n",
       "      <td>80.903905</td>\n",
       "      <td>5.391997</td>\n",
       "      <td>4.880671</td>\n",
       "      <td>90.521405</td>\n",
       "      <td>4.717758e+11</td>\n",
       "      <td>3.317706</td>\n",
       "      <td>12.156409</td>\n",
       "      <td>68.600850</td>\n",
       "      <td>4.122149</td>\n",
       "      <td>...</td>\n",
       "      <td>3.570992e+10</td>\n",
       "      <td>123.367206</td>\n",
       "      <td>18.603427</td>\n",
       "      <td>-8.262401</td>\n",
       "      <td>13.714768</td>\n",
       "      <td>1.085705</td>\n",
       "      <td>1.051149</td>\n",
       "      <td>1.036955</td>\n",
       "      <td>1.015444</td>\n",
       "      <td>1.014810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-13</th>\n",
       "      <td>336.571652</td>\n",
       "      <td>81.746224</td>\n",
       "      <td>5.474510</td>\n",
       "      <td>4.999439</td>\n",
       "      <td>91.538390</td>\n",
       "      <td>4.718107e+11</td>\n",
       "      <td>3.251947</td>\n",
       "      <td>12.620240</td>\n",
       "      <td>76.940893</td>\n",
       "      <td>4.611235</td>\n",
       "      <td>...</td>\n",
       "      <td>3.575691e+10</td>\n",
       "      <td>115.224540</td>\n",
       "      <td>18.930252</td>\n",
       "      <td>-10.789956</td>\n",
       "      <td>21.305058</td>\n",
       "      <td>1.085398</td>\n",
       "      <td>1.050136</td>\n",
       "      <td>1.035781</td>\n",
       "      <td>1.014039</td>\n",
       "      <td>0.865189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-14</th>\n",
       "      <td>336.746076</td>\n",
       "      <td>82.077850</td>\n",
       "      <td>5.490684</td>\n",
       "      <td>5.097688</td>\n",
       "      <td>92.521636</td>\n",
       "      <td>4.718495e+11</td>\n",
       "      <td>3.196375</td>\n",
       "      <td>11.125089</td>\n",
       "      <td>70.331883</td>\n",
       "      <td>3.954675</td>\n",
       "      <td>...</td>\n",
       "      <td>3.580407e+10</td>\n",
       "      <td>102.414438</td>\n",
       "      <td>18.837302</td>\n",
       "      <td>-13.735534</td>\n",
       "      <td>27.261285</td>\n",
       "      <td>1.084133</td>\n",
       "      <td>1.048266</td>\n",
       "      <td>1.033815</td>\n",
       "      <td>1.012107</td>\n",
       "      <td>0.887873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-17</th>\n",
       "      <td>337.502629</td>\n",
       "      <td>83.571584</td>\n",
       "      <td>5.501135</td>\n",
       "      <td>5.178378</td>\n",
       "      <td>96.648836</td>\n",
       "      <td>4.718802e+11</td>\n",
       "      <td>3.116567</td>\n",
       "      <td>9.821778</td>\n",
       "      <td>77.279358</td>\n",
       "      <td>4.183102</td>\n",
       "      <td>...</td>\n",
       "      <td>3.584364e+10</td>\n",
       "      <td>98.451514</td>\n",
       "      <td>18.743343</td>\n",
       "      <td>-16.262957</td>\n",
       "      <td>33.776589</td>\n",
       "      <td>1.084728</td>\n",
       "      <td>1.048209</td>\n",
       "      <td>1.033647</td>\n",
       "      <td>1.011956</td>\n",
       "      <td>0.777970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 close        RSI      MACD    SIGNAL  14 period STOCH %K  \\\n",
       "Date                                                                        \n",
       "2020-08-11  333.588249  75.867466  5.257100  4.752840           80.771767   \n",
       "2020-08-12  336.091889  80.903905  5.391997  4.880671           90.521405   \n",
       "2020-08-13  336.571652  81.746224  5.474510  4.999439           91.538390   \n",
       "2020-08-14  336.746076  82.077850  5.490684  5.097688           92.521636   \n",
       "2020-08-17  337.502629  83.571584  5.501135  5.178378           96.648836   \n",
       "\n",
       "                     MFV  14 period ATR        MOM  14 period MFI       ROC  \\\n",
       "Date                                                                          \n",
       "2020-08-11  4.717004e+11       3.360907  11.852584      60.416619  3.605122   \n",
       "2020-08-12  4.717758e+11       3.317706  12.156409      68.600850  4.122149   \n",
       "2020-08-13  4.718107e+11       3.251947  12.620240      76.940893  4.611235   \n",
       "2020-08-14  4.718495e+11       3.196375  11.125089      70.331883  3.954675   \n",
       "2020-08-17  4.718802e+11       3.116567   9.821778      77.279358  4.183102   \n",
       "\n",
       "            ...         OBV_y  20 period CCI  14 period EMV        VIm  \\\n",
       "Date        ...                                                          \n",
       "2020-08-11  ...  3.565331e+10     116.467862      18.717993  -7.971096   \n",
       "2020-08-12  ...  3.570992e+10     123.367206      18.603427  -8.262401   \n",
       "2020-08-13  ...  3.575691e+10     115.224540      18.930252 -10.789956   \n",
       "2020-08-14  ...  3.580407e+10     102.414438      18.837302 -13.735534   \n",
       "2020-08-17  ...  3.584364e+10      98.451514      18.743343 -16.262957   \n",
       "\n",
       "                  VIp     ema50     ema21     ema15      ema5   normVol  \n",
       "Date                                                                     \n",
       "2020-08-11  11.995666  1.079468  1.045866  1.031954  1.011003  1.110617  \n",
       "2020-08-12  13.714768  1.085705  1.051149  1.036955  1.015444  1.014810  \n",
       "2020-08-13  21.305058  1.085398  1.050136  1.035781  1.014039  0.865189  \n",
       "2020-08-14  27.261285  1.084133  1.048266  1.033815  1.012107  0.887873  \n",
       "2020-08-17  33.776589  1.084728  1.048209  1.033647  1.011956  0.777970  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before we produced the prediction data, we grabbed this small dataframe to use in actual testing\n",
    "live_pred_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "del(live_pred_data['close'])\n",
    "prediction = ensemble_model.predict(live_pred_data)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
